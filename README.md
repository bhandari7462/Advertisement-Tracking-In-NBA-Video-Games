# Advertisement-Tracking-In-NBA-Video-Games

An end-to-end computer vision pipeline designed to automatically detect and track brand advertisements in NBA game videos. Leveraging OCR, deep learning models, and asynchronous video processing, the system extracts frames from YouTube-hosted game footage, identifies brand names through text recognition, and compiles the results into visually rich PDF reports. All processing is seamlessly triggered and managed via an intuitive, user-friendly web interface.

---

## Key Features

- **YouTube Video Processing** ‚Äì Download and preprocess NBA game videos using `yt-dlp`.
- **OCR Text Extraction** ‚Äì Apply a fine-tuned PaddleOCR model for high-accuracy brand text detection.
- **Fuzzy Matching** ‚Äì Correct OCR inaccuracies and match brand names using `RapidFuzz`.
- **Automated Email Reporting** ‚Äì Generate PDF reports and deliver them directly to users via email.
- **REST API with FastAPI** ‚Äì Enable seamless video-to-report analysis through simple HTTP requests.
- **Modular Pipeline Design** ‚Äì Maintain clean separation of concerns across download, OCR, matching, and reporting stages.
---

## Tech Stack

| Layer         | Tools & Libraries |
|---------------|-------------------|
| Language      | Python 3.8+        |
| Video         | `yt-dlp`, `OpenCV`, `ffmpeg-python` |
| OCR Models    | `Fine-tuned PaddleOCR`, `PaddleOCR` |
| API Framework | `FastAPI`, `uvicorn` |
| Matching      | `RapidFuzz`, `fuzzywuzzy` |
| Async Engine  | `Celery`, `Redis` |
| Reports       | `email`, `Deatiled PDF` |


---

## Setup & Installation

### 1. Clone the Repository

```bash
git clone https://github.com/faijan-khan/NBA.git
```

### 2. Create a Virtual Environment

```bash
conda create --name nba python=3.10 -y
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```


### 4. Set Email Credentials

Create a `.env` file in the root directory:

```env
SMTP_HOST=smtp.gmail.com
SMTP_PORT=desired prt
SMTP_USER=your-email@gmail.com
SMTP_PASSWORD=your-app-password
REDIS_URL=your-redis-url
```

---

## Running the App

### Start Redis server first (use wsl for windows)

```bash
wsl
redis-server
redis-cli ping
```
(you should see PONG)
### Run Celery worker (new terminal)

```bash
conda activate nba
cd backend
celery -A worker.celery_app worker --loglevel=info --pool=solo
```
### Start FastAPI server (new terminal)

```bash
conda activate nba
cd backend
uvicorn main:app --reload
```

API is available at:
`http://localhost:8000`
Interactive Docs: [`/docs`](http://localhost:8000/docs)

---
## Frontend Usage (Web UI)

The application includes a user-friendly web interface for easy interaction with the NBA advertisement detection pipeline.

### Step-by-Step UI Process

#### 1. **Access the Web Interface**
Navigate to `http://localhost:8000` in your browser to access the main interface.

![](step1.png)

#### 2. **Fill Out the Analysis Form**
- **YouTube URL**: Paste the NBA game video URL (e.g., `https://www.youtube.com/watch?v=VIDEO_ID`)
- **Email Address**: Enter your email to receive the analysis report
- **OCR Model**: Select between `fine-tuned paddleocr` or `pretrained paddleocr` for text detection
- **Brand List**: Select brands to detect (Popular brands are added)

![](step2.png)

#### 3. **Submit Analysis Request**
Click the "Start Analysis" button to trigger the pipeline processing.

#### 4. **Receive Task Confirmation**
The UI displays a confirmation message.

![](step4.png)

#### 5. **Monitor Progress** *(Optional)*
Use the task ID to check processing status via the `/result/{task_id}` endpoint.

![](step5.png)

#### 6. **Get Results**
- **Email**: Receive the PDF report directly in your inbox
- **Download**: Access the PDF report via the result endpoint when processing completes
- **CSV files**: Get the .csv files for individual as well as total brand analysis
- **Json file**: Get a .json file to see which brand is matched with which keyword

![](step6.png)

---

## Backend Process Flow

Here's how the system processes your request behind the scenes:

### 1. **Request Reception** 
```
POST /analyze ‚Üí FastAPI receives form data
‚îú‚îÄ‚îÄ Validates required fields (URL, email, brands)
‚îú‚îÄ‚îÄ Generates unique timestamp
‚îî‚îÄ‚îÄ Creates Celery task via run_pipeline_task.delay()
```

### 2. **Task Queuing** 
```
Celery Worker picks up task
‚îú‚îÄ‚îÄ Task ID: a1b2c3d4-e5f6-7890-abcd-ef1234567890
‚îú‚îÄ‚îÄ Status: PENDING ‚Üí STARTED
‚îî‚îÄ‚îÄ Parameters passed to pipeline_runner.py
```

### 3. **Video Processing** 
```
Pipeline Execution:
‚îú‚îÄ‚îÄ Download video using yt-dlp
‚îú‚îÄ‚îÄ Extract frames at 1 FPS using ffmpeg
‚îú‚îÄ‚îÄ Save frames to /downloads/model/url_id/frames/
‚îî‚îÄ‚îÄ Log progress to console
```

### 4. **OCR Text Detection** 
```
Text Extraction:
‚îú‚îÄ‚îÄ Load selected OCR model
‚îú‚îÄ‚îÄ Process each frame for text detection
‚îú‚îÄ‚îÄ Extract text coordinates and confidence scores
‚îî‚îÄ‚îÄ Save results to /downloads/model/url_id/paddle_ouput/
```

### 5. **Brand Matching** 
```
Fuzzy Matching Process:
‚îú‚îÄ‚îÄ Compare detected text against brand list
‚îú‚îÄ‚îÄ Use RapidFuzz for similarity scoring
‚îú‚îÄ‚îÄ Apply threshold filtering (e.g., >80% similarity)
‚îú‚îÄ‚îÄ Compile brand mentions with timestamps
‚îî‚îÄ‚îÄ Save results to /downloads/model/url_id/ brand_analysis.csv, brand_totals.csv, brand_match_log.json
```

### 6. **Report Generation** 
```
PDF Creation:
‚îú‚îÄ‚îÄ Aggregate all brand detections
‚îú‚îÄ‚îÄ Include frame timestamps and confidence scores
‚îú‚îÄ‚îÄ Generate professional PDF report
‚îî‚îÄ‚îÄ Save to /downloads/model/url_id/brand_report_enhanced.pdf
```

### 7. **Email Delivery** 
```
Email Service:
‚îú‚îÄ‚îÄ Compose professional email with results summary
‚îú‚îÄ‚îÄ Attach PDF report
‚îú‚îÄ‚îÄ Send via configured SMTP (Gmail)
‚îî‚îÄ‚îÄ Log delivery status
```

### 8. **Task Completion** 
```
Final Status Update:
‚îú‚îÄ‚îÄ Task Status: STARTED ‚Üí SUCCESS
‚îú‚îÄ‚îÄ Save logs at /downloads/model/url_id/pipeline.log
‚îî‚îÄ‚îÄ Clean up temporary files (optional)
```

### 9. **Result Retrieval** 
```
GET/
‚îú‚îÄ‚îÄ Check task status via Celery
‚îú‚îÄ‚îÄ Return processing/failed/success status
‚îú‚îÄ‚îÄ Serve PDF file download if completed
‚îî‚îÄ‚îÄ Handle file not found errors
```

---
##  API Usage

### Endpoint: `POST /analyze`

#### Sample Request Body

```json
{
  "youtubeUrl": "https://www.youtube.com/watch?v=VIDEO_ID",
  "brands": ["statefarm", "coinbase", "youtubetv"],
  "email": "user@example.com",
  "model": "keras-ocr",
  "timestamp": "20250617_143000"
}
```

#### Sample Response

```json
{
  "message": "Pipeline triggered!",
  "task_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890"
}
```

### Endpoint: `GET /result/{task_id}`
```
Check the status of your analysis and download the PDF report.
```

---

## Pipeline Architecture

1. **Download Video** ‚Üí `yt-dlp`
2. **Extract Frames** ‚Üí `ffmpeg` (default 1 FPS)
3. **Run OCR** ‚Üí `PaddleOCR or Fine-tuned PaddleOCR`
4. **Fuzzy Match Brands** ‚Üí `RapidFuzz`
5. **Compile Results** ‚Üí Final PDF report
6. **Email Output** ‚Üí Auto-sent to user

---

## Directory Layout

```
backend
    ‚îú‚îÄ‚îÄ main.py 
    ‚îú‚îÄ‚îÄ pipeline.py 
    ‚îú‚îÄ‚îÄ worker.py
    ‚îú‚îÄ‚îÄ celery_config.py
    ‚îú‚îÄ‚îÄ tasks/
        ‚îú‚îÄ‚îÄ inference/ # Fine-tuned inferences
        ‚îú‚îÄ‚îÄ count.py
        ‚îú‚îÄ‚îÄ download_and_extract_frames.py
        ‚îú‚îÄ‚îÄ ocr.py
        ‚îú‚îÄ‚îÄ report.py
        ‚îú‚îÄ‚îÄ visual.py
    ‚îú‚îÄ‚îÄ utils/
        ‚îú‚îÄ‚îÄ emailer.py
frontend
    ‚îú‚îÄ‚îÄ index.html
    ‚îú‚îÄ‚îÄ style.css 
    ‚îú‚îÄ‚îÄ script.js
.env # Email credentials, DB configs


```

---



## Security Best Practices

* Store sensitive info in `.env`
* Sanitize YouTube links
* Add file size and video length limits
* Implement rate limiting if hosted publicly

---

## üìú License

MIT License. See [LICENSE](LICENSE) for full details.

---

## üôå Acknowledgments

This project would not have been possible without the contributions and inspiration from the following open-source projects, frameworks, and individuals:

- [Keras-OCR](https://github.com/faizanvadsaria/Keras-OCR)  
- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)  
- [yt-dlp](https://github.com/yt-dlp/yt-dlp)  
- [FastAPI](https://fastapi.tiangolo.com/)  
- [OpenCV](https://opencv.org/)  
- [RapidFuzz](https://github.com/maxbachmann/RapidFuzz)  
- [FFmpeg](https://ffmpeg.org/)  
- [Celery](https://docs.celeryq.dev/)  
- [Redis](https://redis.io/)  
- [LabelMe](http://labelme.csail.mit.edu/)   
- [Sabudh Foundation](https://sabudh.org/)  
- Special thanks to **Mr. Bappaditya Mukhopadhyay**, **Mr. Divjot Singh**, and **Mr. Harjaspreet Singh** for guidance during the project


---

## üì¨ Contact

Created by [Kishan Bhandari](https://github.com/bhandari7462)
üìß [kishan2003bhandari@gmail.com](mailto:kishan2003bhandari@gmail.com)

---

> ‚ö†Ô∏è For educational and research purposes only. Respect YouTube's TOS and copyright laws.
